# spider

#### ä»€ä¹ˆæ˜¯äº’è”ç½‘çˆ¬è™«ï¼Ÿ

```
1.é€šè¿‡ä¸€ä¸ªç¨‹åºï¼Œæ ¹æ®Urlè¿›è¡Œçˆ¬å–ç½‘é¡µï¼Œè·å–æœ‰ç”¨ä¿¡æ¯
2.ä½¿ç”¨ç¨‹åºæ¨¡æ‹Ÿæµè§ˆå™¨ï¼Œå»å‘æœåŠ¡å™¨å‘é€è¯·æ±‚ï¼Œè·å–å“åº”ä¿¡æ¯
```

#### çˆ¬è™«æ ¸å¿ƒ?

```
1.çˆ¬å–ç½‘é¡µï¼šçˆ¬å–æ•´ä¸ªç½‘é¡µ  åŒ…å«äº†ç½‘é¡µä¸­æ‰€æœ‰å¾—å†…å®¹
2.è§£ææ•°æ®ï¼šå°†ç½‘é¡µä¸­ä½ å¾—åˆ°çš„æ•°æ® è¿›è¡Œè§£æ
3.éš¾ç‚¹ï¼šçˆ¬è™«å’Œåçˆ¬è™«ä¹‹é—´çš„åšå¼ˆ
```

#### çˆ¬è™«çš„ç”¨é€”ï¼Ÿ

- æ•°æ®åˆ†æ/äººå·¥æ•°æ®é›†
- ç¤¾äº¤è½¯ä»¶å†·å¯åŠ¨
- èˆ†æƒ…ç›‘æ§
- ç«äº‰å¯¹æ‰‹ç›‘æ§

#### çˆ¬è™«è¯­è¨€åˆ†ç±»ï¼Ÿ

```
1.php:å¤šè¿›ç¨‹å’Œå¤šçº¿ç¨‹æ”¯æŒä¸å¥½
2.java:ç›®å‰javaçˆ¬è™«éœ€æ±‚å²—ä½æ—ºç››ï¼Œpythonçˆ¬è™«çš„ä¸»è¦å¯¹æ‰‹ï¼Œä»£ç è‡ƒè‚¿ï¼Œä»£ç é‡å¤§ã€é‡æ„æˆæœ¬é«˜ï¼Œè€Œçˆ¬è™«éœ€è¦ç»å¸¸ä¿®æ”¹ï¼Œæ‰€ä»¥ä¸å¥½ç”¨
3.C\C++:å­¦ä¹ æˆæœ¬æ¯”è¾ƒé«˜ï¼Œæ€§èƒ½å’Œæ•ˆç‡é«˜ï¼Œåœç•™åœ¨ç ”ç©¶å±‚é¢ï¼Œå¸‚åœºéœ€æ±‚é‡å°ã€‚ä½“ç°ç¨‹åºå‘˜èƒ½åŠ›ã€‚
4.python:è¯­æ³•ç®€æ´ä¼˜ç¾ã€å¯¹æ–°æ‰‹å‹å¥½ï¼Œå­¦ä¹ æˆæœ¬ä½ã€æ”¯æŒçš„æ¨¡å—éå¸¸å¤šã€æœ‰scrapyéå¸¸å¼ºå¤§çš„çˆ¬è™«æ¡†æ¶
```

#### çˆ¬è™«åˆ†ç±»ï¼Ÿ

```
é€šç”¨çˆ¬è™«ï¼š
	å®ä¾‹
		ç™¾åº¦ã€360ã€googleã€sougouç­‰æœç´¢å¼•æ“---ä¼¯ä¹åœ¨çº¿
	åŠŸèƒ½
		è®¿é—®ç½‘é¡µ->æŠ“å–æ•°æ®->æ•°æ®å­˜å‚¨->æ•°æ®å¤„ç†->æä¾›æ£€ç´¢æœåŠ¡
	robotsåè®®
		ä¸€ä¸ªçº¦å®šä¿—æˆçš„åè®®ï¼Œæ·»åŠ robots.txtæ–‡ä»¶ï¼Œæ¥è¯´æ˜æœ¬ç½‘ç«™å“ªäº›å†…å®¹ä¸å¯ä»¥è¢«æŠ“å–ï¼Œèµ·ä¸åˆ°é™åˆ¶ä½œç”¨
		è‡ªå·±å†™çš„çˆ¬è™«æ— éœ€éµå®ˆ
	ç½‘ç«™æ’å(SEO)
		1. æ ¹æ®pagerankç®—æ³•å€¼è¿›è¡Œæ’åï¼ˆå‚è€ƒä¸ªç½‘ç«™æµé‡ã€ç‚¹å‡»ç‡ç­‰æŒ‡æ ‡ï¼‰
		2. ç™¾åº¦ç«ä»·æ’åï¼Œé’±å¤šå°±æ˜¯çˆ¸çˆ¸
	ç¼ºç‚¹
		1. æŠ“å–çš„æ•°æ®å¤§å¤šæ˜¯æ— ç”¨çš„
		2.ä¸èƒ½æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚æ¥ç²¾å‡†è·å–æ•°æ®
```

```
èšç„¦çˆ¬è™«
	åŠŸèƒ½
		æ ¹æ®éœ€æ±‚ï¼Œå®ç°çˆ¬è™«ç¨‹åºï¼ŒæŠ“å–éœ€è¦çš„æ•°æ®
	åŸç†
		1.ç½‘é¡µéƒ½æœ‰è‡ªå·±å”¯ä¸€çš„url(ç»Ÿä¸€èµ„æºå®šä½ç¬¦ï¼‰
		2.ç½‘é¡µéƒ½æ˜¯htmlç»„æˆ
		3.ä¼ è¾“åè®®éƒ½æ˜¯http\https
	è®¾è®¡æ€è·¯
		1.ç¡®å®šè¦çˆ¬å–çš„url
			å¦‚ä½•è·å–Url
		2.æ¨¡æ‹Ÿæµè§ˆå™¨é€šè¿‡httpåè®®è®¿é—®urlï¼Œè·å–æœåŠ¡å™¨è¿”å›çš„htmlä»£ç 
			å¦‚ä½•è®¿é—®
		3.è§£æhtmlå­—ç¬¦ä¸²ï¼ˆæ ¹æ®ä¸€å®šè§„åˆ™æå–éœ€è¦çš„æ•°æ®ï¼‰
			å¦‚ä½•è§£æ
```

#### åçˆ¬æ‰‹æ®µï¼Ÿ

```
1.User-Agentï¼š
	User Agentä¸­æ–‡åä¸ºç”¨æˆ·ä»£ç†ï¼Œç®€ç§° UAï¼Œå®ƒæ˜¯ä¸€ä¸ªç‰¹æ®Šå­—ç¬¦ä¸²å¤´ï¼Œä½¿å¾—æœåŠ¡å™¨èƒ½å¤Ÿè¯†åˆ«å®¢æˆ·ä½¿ç”¨çš„æ“ä½œç³»ç»ŸåŠç‰ˆæœ¬ã€CPU ç±»å‹ã€æµè§ˆå™¨åŠç‰ˆæœ¬ã€æµè§ˆå™¨æ¸²æŸ“å¼•æ“ã€æµè§ˆå™¨è¯­è¨€ã€æµè§ˆå™¨æ’ä»¶ç­‰ã€‚
2.ä»£ç†IP
	è¥¿æ¬¡ä»£ç†
	å¿«ä»£ç†
	ä»€ä¹ˆæ˜¯é«˜åŒ¿åã€åŒ¿åå’Œé€æ˜ä»£ç†ï¼Ÿå®ƒä»¬æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ
		1.ä½¿ç”¨é€æ˜ä»£ç†ï¼Œå¯¹æ–¹æœåŠ¡å™¨å¯ä»¥çŸ¥é“ä½ ä½¿ç”¨äº†ä»£ç†ï¼Œå¹¶ä¸”ä¹ŸçŸ¥é“ä½ çš„çœŸå®IPã€‚
		2.ä½¿ç”¨åŒ¿åä»£ç†ï¼Œå¯¹æ–¹æœåŠ¡å™¨å¯ä»¥çŸ¥é“ä½ ä½¿ç”¨äº†ä»£ç†ï¼Œä½†ä¸çŸ¥é“ä½ çš„çœŸå®IPã€‚
		3.ä½¿ç”¨é«˜åŒ¿åä»£ç†ï¼Œå¯¹æ–¹æœåŠ¡å™¨ä¸çŸ¥é“ä½ ä½¿ç”¨äº†ä»£ç†ï¼Œæ›´ä¸çŸ¥é“ä½ çš„çœŸå®IPã€‚
3.éªŒè¯ç è®¿é—®
	æ‰“ç å¹³å°
      äº‘æ‰“ç å¹³å°
      è¶…çº§ğŸ¦…
4.åŠ¨æ€åŠ è½½ç½‘é¡µ  ç½‘ç«™è¿”å›çš„æ˜¯jsæ•°æ® å¹¶ä¸æ˜¯ç½‘é¡µçš„çœŸå®æ•°æ® 
	seleniumé©±åŠ¨çœŸå®çš„æµè§ˆå™¨å‘é€è¯·æ±‚
5.æ•°æ®åŠ å¯†  
	åˆ†æjsä»£ç 
	
çˆ¬è™«-åçˆ¬è™«-ååçˆ¬è™«
```

#### Httpåè®®

```
1.httpå’ŒhttpsåŒºåˆ«ï¼Ÿ
	http
		æ˜æ–‡ä¼ è¾“ï¼Œç«¯å£å·80
		HTTPåè®®ï¼ˆHyperText Transfer Protocolï¼Œè¶…æ–‡æœ¬ä¼ è¾“åè®®ï¼‰ï¼šæ˜¯ä¸€ç§å‘å¸ƒå’Œæ¥æ”¶ HTMLé¡µé¢çš„æ–¹æ³•ã€‚

	https
		åŠ å¯†ä¼ è¾“ï¼Œç«¯å£å·443
		HTTPSï¼ˆHypertext Transfer Protocol over Secure Socket Layerï¼‰ç®€å•è®²æ˜¯HTTPçš„å®‰å…¨ç‰ˆï¼Œåœ¨HTTPä¸‹åŠ å…¥SSLå±‚ã€‚    HTTPS = HTTP+SSL

		SSLï¼ˆSecure Sockets Layer å®‰å…¨ å¥—æ¥å±‚ï¼‰ä¸»è¦ç”¨äºWebçš„å®‰å…¨ä¼ è¾“åè®®ï¼Œåœ¨ä¼ è¾“å±‚å¯¹ç½‘ç»œè¿æ¥è¿›è¡ŒåŠ å¯†ï¼Œä¿éšœåœ¨Internetä¸Šæ•°æ®ä¼ è¾“çš„å®‰å…¨ã€‚
2.ä»€ä¹ˆæ˜¯SSLï¼Ÿ
	SSL
		ä»€ä¹ˆæ˜¯å®‰å…¨è®¤è¯
		å…³äºCA
		12306ç½‘ç«™è¯ä¹¦æ˜¯è‡ªå·±çš„
		å®‰å…¨è®¤è¯requests
		å®‰å…¨è®¤è¯urllib
	æ³¨æ„ï¼šå¦‚æœæŠ¥é”™SSL,é‚£ä¹ˆè§£å†³æ–¹æ¡ˆæ˜¯
              import urllib.request
              import ssl
              ssl._create_default_https_context = ssl._create_unverified_context
3.å¸¸è§æœåŠ¡å™¨ç«¯å£å·
		ftp      21
		ssh      22
		mysql    3306
		oracle   1521
		MongoDB  27017
		redis    6379
	httpå·¥ä½œåŸç†
		urlç»„æˆ
			åè®®	ä¸»æœº   ç«¯å£å·  è·¯å¾„   å‚æ•°  é”šç‚¹
		ä¸Šç½‘åŸç†
		httpè¯·æ±‚å’Œå“åº”
			è¯·æ±‚è¡Œ.è¯·æ±‚å¤´ã€è¯·æ±‚ä½“
			å“åº”è¡Œ.å“åº”å¤´ã€å“åº”ä½“
			è¯·æ±‚å¤´è¯¦è§£
				Accept
				Accept-Encoding
				Accept-Language
				Cache-Control
				Connection
				Cookie
				Host
				Upgrade-Insecure-Requests    httpæ˜¯å¦å‡çº§ä¸ºhttps
				User-Agent 
				X-Requested-With             æ˜¯å¦æ˜¯ajaxè¯·æ±‚             
				Referer                      ä¸Šä¸€çº§è·¯å¾„
			å“åº”å¤´è¯¦è§£
				Connection
				Content-Encoding
				Content-Type
				Date
				Expires
				Server
				Transfer-Encoding            å†…å®¹æ˜¯å¦åˆ†åŒ…ä¼ è¾“
			å¸¸è§HTTPçŠ¶æ€ç 
				200
					è¯·æ±‚æˆåŠŸ
				404
					æœªæ‰¾åˆ°èµ„æº
				500
					æœåŠ¡å™¨å†…éƒ¨é”™è¯¯
```



#### urllibåº“ä½¿ç”¨

```
	urllib.request.urlopen() æ¨¡æ‹Ÿæµè§ˆå™¨å‘æœåŠ¡å™¨å‘é€è¯·æ±‚
	response    æœåŠ¡å™¨è¿”å›çš„æ•°æ®
		responseçš„æ•°æ®ç±»å‹æ˜¯HttpResponse
		å­—èŠ‚-->å­—ç¬¦ä¸²
				è§£ç decode
		å­—ç¬¦ä¸²-->å­—èŠ‚
				ç¼–ç encode
		read()       å­—èŠ‚å½¢å¼è¯»å–äºŒè¿›åˆ¶   æ‰©å±•ï¼šrede(5)è¿”å›å‰å‡ ä¸ªå­—èŠ‚
		readline()   è¯»å–ä¸€è¡Œ
		readlines()  ä¸€è¡Œä¸€è¡Œè¯»å– ç›´è‡³ç»“æŸ
		getcode()    è·å–çŠ¶æ€ç 
		geturl()     è·å–url
		getheaders() è·å–headers
	urllib.request.urlretrieve()
		è¯·æ±‚ç½‘é¡µ
		è¯·æ±‚å›¾ç‰‡
		è¯·æ±‚è§†é¢‘
```

```
pycharmä»£ç ä¾‹å­ï¼š

import urllib.request
url='http://www.baidu.com'
# ä½¿ç”¨urllibè®¿é—®urlè·¯å¾„
response = urllib.request.urlopen(url=url)
# å¾—åˆ°responseå³ä½¿è®¿é—®è·¯å¾„çš„å“åº”,å¯ä»¥ä½¿ç”¨æ–¹æ³•è¯»å–å†…å®¹
content = response.read()  
# éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¯»å–çš„å†…å®¹æ˜¯äºŒè¿›åˆ¶ï¼Œ
# ä¸€èˆ¬çš„å†…å®¹ç¼–ç éƒ½æ˜¯utf-8 
# ä¹Ÿæœ‰è‡ªå®šä¹‰ç¼–ç çš„ç½‘é¡µï¼Œæ ¹æ®ç½‘é¡µä¸­metaçš„charsetæ¥è§£ç 
content = content.decode('utf-8')
# æ­¤æ—¶çš„contentå°±æ˜¯è®¿é—®urlå¾—åˆ°çš„å†…å®¹
# è®¸å¤šç½‘é¡µæ·»åŠ äº†åæ‰’æ‰‹æ®µï¼Œä»…ä»…ä½¿ç”¨è¿™äº›ä»£ç å¹¶ä¸èƒ½å¾—åˆ°çœŸæ­£çš„æºç 

#ä½¿ç”¨urllibä¸‹è½½å›¾ç‰‡ï¼Œä¸‹è½½è§†é¢‘ã€éŸ³é¢‘
url=`src`
# è¿™é‡Œçš„srcæ˜¯å›¾ç‰‡æˆ–è€…è§†é¢‘èµ„æºçš„ä¸‹è½½è·¯å¾„

urllib.request.urlretrieve(url=url,filename='diy.jpg')
#æ­¤æ—¶ä¼šå°†è·¯å¾„å¾—åˆ°çš„å†…å®¹ä¸‹è½½åˆ°æœ¬åœ°ï¼Œå¹¶ä¸€filenameå‘½å

```



æ‰©å±•ï¼šç¼–ç çš„ç”±æ¥

```
'''ç¼–ç é›†çš„æ¼”å˜---
ç”±äºè®¡ç®—æœºæ˜¯ç¾å›½äººå‘æ˜çš„ï¼Œå› æ­¤ï¼Œæœ€æ—©åªæœ‰127ä¸ªå­—ç¬¦è¢«ç¼–ç åˆ°è®¡ç®—æœºé‡Œï¼Œä¹Ÿå°±æ˜¯å¤§å°å†™è‹±æ–‡å­—æ¯ã€æ•°å­—å’Œä¸€äº›ç¬¦å·ï¼Œ
è¿™ä¸ªç¼–ç è¡¨è¢«ç§°ä¸ºASCIIç¼–ç ï¼Œæ¯”å¦‚å¤§å†™å­—æ¯Açš„ç¼–ç æ˜¯65ï¼Œå°å†™å­—æ¯zçš„ç¼–ç æ˜¯122ï¼Œ0çš„ç¼–ç æ˜¯48ã€‚
ä½†æ˜¯è¦å¤„ç†ä¸­æ–‡æ˜¾ç„¶ä¸€ä¸ªå­—èŠ‚æ˜¯ä¸å¤Ÿçš„ï¼Œè‡³å°‘éœ€è¦ä¸¤ä¸ªå­—èŠ‚ï¼Œè€Œä¸”è¿˜ä¸èƒ½å’ŒASCIIç¼–ç å†²çªï¼Œ
æ‰€ä»¥ï¼Œä¸­å›½åˆ¶å®šäº†GB2312ç¼–ç ï¼Œç”¨æ¥æŠŠä¸­æ–‡ç¼–è¿›å»ã€‚
ä½ å¯ä»¥æƒ³å¾—åˆ°çš„æ˜¯ï¼Œå…¨ä¸–ç•Œæœ‰ä¸Šç™¾ç§è¯­è¨€ï¼Œæ—¥æœ¬æŠŠæ—¥æ–‡ç¼–åˆ°Shift_JISé‡Œï¼ŒéŸ©å›½æŠŠéŸ©æ–‡ç¼–åˆ°Euc-kré‡Œï¼Œ
å„å›½æœ‰å„å›½çš„æ ‡å‡†ï¼Œå°±ä¼šä¸å¯é¿å…åœ°å‡ºç°å†²çªï¼Œç»“æœå°±æ˜¯ï¼Œåœ¨å¤šè¯­è¨€æ··åˆçš„æ–‡æœ¬ä¸­ï¼Œæ˜¾ç¤ºå‡ºæ¥ä¼šæœ‰ä¹±ç ã€‚
å› æ­¤ï¼ŒUnicodeåº”è¿è€Œç”Ÿã€‚UnicodeæŠŠæ‰€æœ‰è¯­è¨€éƒ½ç»Ÿä¸€åˆ°ä¸€å¥—ç¼–ç é‡Œï¼Œè¿™æ ·å°±ä¸ä¼šå†æœ‰ä¹±ç é—®é¢˜äº†ã€‚
Unicodeæ ‡å‡†ä¹Ÿåœ¨ä¸æ–­å‘å±•ï¼Œä½†æœ€å¸¸ç”¨çš„æ˜¯ç”¨ä¸¤ä¸ªå­—èŠ‚è¡¨ç¤ºä¸€ä¸ªå­—ç¬¦ï¼ˆå¦‚æœè¦ç”¨åˆ°éå¸¸ååƒ»çš„å­—ç¬¦ï¼Œå°±éœ€è¦4ä¸ªå­—èŠ‚ï¼‰ã€‚
ç°ä»£æ“ä½œç³»ç»Ÿå’Œå¤§å¤šæ•°ç¼–ç¨‹è¯­è¨€éƒ½ç›´æ¥æ”¯æŒUnicodeã€‚'''

```

#### è¯·æ±‚å¯¹è±¡çš„å®šåˆ¶

```
UAä»‹ç»ï¼šUser Agentä¸­æ–‡åä¸ºç”¨æˆ·ä»£ç†ï¼Œç®€ç§° UAï¼Œå®ƒæ˜¯ä¸€ä¸ªç‰¹æ®Šå­—ç¬¦ä¸²å¤´ï¼Œä½¿å¾—æœåŠ¡å™¨èƒ½å¤Ÿè¯†åˆ«å®¢æˆ·ä½¿ç”¨çš„æ“ä½œç³»ç»ŸåŠç‰ˆæœ¬ã€CPU ç±»å‹ã€æµè§ˆå™¨åŠç‰ˆæœ¬ã€‚æµè§ˆå™¨å†…æ ¸ã€æµè§ˆå™¨æ¸²æŸ“å¼•æ“ã€æµè§ˆå™¨è¯­è¨€ã€æµè§ˆå™¨æ’ä»¶ç­‰

```

```
è¯­æ³•ï¼šrequest = urllib.request.Request()

```



#### 1ç¼–è§£ç 

###### 1.getè¯·æ±‚æ–¹å¼ï¼šurllib.parse.quoteï¼ˆï¼‰

```
egï¼š
import urllib.request
import urllib.parse

url = 'https://www.baidu.com/s?wd='

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36'
}

url = url + urllib.parse.quote('å°é‡')

request = urllib.request.Request(url=url,headers=headers)

response = urllib.request.urlopen(request)

print(response.read().decode('utf-8'))

```

```
ajaxçš„getè¯·æ±‚ä¾‹å­ï¼š

import urllib.request 
import urllib.parse

url = 'http://â€¦â€¦'

data={
	'kw':'data1',
	'wd':'data2',
}

headers = {
	    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36',

}

# ä½¿ç”¨urllib.parseè¿›è¡Œè½¬ç 
# quote è¿›è¡Œå•ä¸ªæ•°æ®è½¬ç 
# data = urllib.parse.quote('æœç´¢å†…å®¹') 


```













###### 2.getè¯·æ±‚æ–¹å¼ï¼šurllib.parse.urlencodeï¼ˆï¼‰

```
eg:
import urllib.request
import urllib.parse
url = 'http://www.baidu.com/s?'
data = {
    'name':'å°åˆš',
    'sex':'ç”·',
}
data = urllib.parse.urlencode(data)
url = url + data
print(url)
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36'
}
request = urllib.request.Request(url=url,headers=headers)
response = urllib.request.urlopen(request)
print(response.read().decode('utf-8'))

```

###### 3.postè¯·æ±‚æ–¹å¼

```
eg:ç™¾åº¦ç¿»è¯‘
import urllib.request
import urllib.parse
url = 'https://fanyi.baidu.com/sug'
headers = {
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36'
}
keyword = input('è¯·è¾“å…¥æ‚¨è¦æŸ¥è¯¢çš„å•è¯')
data = {
    'kw':keyword
}
data = urllib.parse.urlencode(data).encode('utf-8')
request = urllib.request.Request(url=url,headers=headers,data=data)
response = urllib.request.urlopen(request)
print(response.read().decode('utf-8'))

```

æ€»ç»“ï¼špostå’ŒgetåŒºåˆ«ï¼Ÿ

```
1ï¼šgetè¯·æ±‚æ–¹å¼çš„å‚æ•°å¿…é¡»ç¼–ç ï¼Œå‚æ•°æ˜¯æ‹¼æ¥åˆ°urlåé¢ï¼Œç¼–ç ä¹‹åä¸éœ€è¦è°ƒç”¨encodeæ–¹æ³•
2ï¼špostè¯·æ±‚æ–¹å¼çš„å‚æ•°å¿…é¡»ç¼–ç ï¼Œå‚æ•°æ˜¯æ”¾åœ¨è¯·æ±‚å¯¹è±¡å®šåˆ¶çš„æ–¹æ³•ä¸­ï¼Œç¼–ç ä¹‹åéœ€è¦è°ƒç”¨encodeæ–¹æ³•

```

æ¡ˆä¾‹ç»ƒä¹ ï¼šç™¾åº¦è¯¦ç»†ç¿»è¯‘

```
import urllib.request
import urllib.parse

url = 'https://fanyi.baidu.com/v2transapi'
headers = {
    # ':authority': 'fanyi.baidu.com',
    # ':method': 'POST',
    # ':path': '/v2transapi',
    # ':scheme': 'https',
    # 'accept': '*/*',
    # 'accept-encoding': 'gzip, deflate, br',
    # 'accept-language': 'zh-CN,zh;q=0.9',
    # 'content-length': '119',
    # 'content-type': 'application/x-www-form-urlencoded; charset=UTF-8',
    'cookie': 'REALTIME_TRANS_SWITCH=1; FANYI_WORD_SWITCH=1; HISTORY_SWITCH=1; SOUND_SPD_SWITCH=1; SOUND_PREFER_SWITCH=1; PSTM=1537097513; BIDUPSID=D96F9A49A8630C54630DD60CE082A55C; BAIDUID=0814C35D13AE23F5EAFA8E0B24D9B436:FG=1; to_lang_often=%5B%7B%22value%22%3A%22en%22%2C%22text%22%3A%22%u82F1%u8BED%22%7D%2C%7B%22value%22%3A%22zh%22%2C%22text%22%3A%22%u4E2D%u6587%22%7D%5D; from_lang_often=%5B%7B%22value%22%3A%22zh%22%2C%22text%22%3A%22%u4E2D%u6587%22%7D%2C%7B%22value%22%3A%22en%22%2C%22text%22%3A%22%u82F1%u8BED%22%7D%5D; BDORZ=B490B5EBF6F3CD402E515D22BCDA1598; delPer=0; H_PS_PSSID=1424_21115_29522_29519_29099_29568_28835_29220_26350; PSINO=2; locale=zh; Hm_lvt_64ecd82404c51e03dc91cb9e8c025574=1563000604,1563334706,1565592510; Hm_lpvt_64ecd82404c51e03dc91cb9e8c025574=1565592510; yjs_js_security_passport=2379b52646498f3b5d216e6b21c6f1c7bf00f062_1565592544_js',
    # 'origin': 'https://fanyi.baidu.com',
    # 'referer': 'https://fanyi.baidu.com/translate?aldtype=16047&query=&keyfrom=baidu&smartresult=dict&lang=auto2zh',
    # 'sec-fetch-mode': 'cors',
    # 'sec-fetch-site': 'same-origin',
    # 'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36',
    # 'x-requested-with': 'XMLHttpRequest',
}
data = {
    'from': 'en',
    'to': 'zh',
    'query': 'you',
    'transtype': 'realtime',
    'simple_means_flag': '3',
    'sign': '269482.65435',
    'token': '2e0f1cb44414248f3a2b49fbad28bbd5',
}
#å‚æ•°çš„ç¼–ç 
data = urllib.parse.urlencode(data).encode('utf-8')
# è¯·æ±‚å¯¹è±¡çš„å®šåˆ¶
request = urllib.request.Request(url=url,headers=headers,data=data)
response = urllib.request.urlopen(request)
# è¯·æ±‚ä¹‹åè¿”å›çš„æ‰€æœ‰çš„æ•°æ®
content = response.read().decode('utf-8')
import json
# loadså°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºpythonå¯¹è±¡
obj = json.loads(content)
# pythonå¯¹è±¡è½¬æ¢ä¸ºjsonå­—ç¬¦ä¸²  ensure_ascii=False  å¿½ç•¥å­—ç¬¦é›†ç¼–ç 
s = json.dumps(obj,ensure_ascii=False)
print(s)

```

#### ajaxçš„getè¯·æ±‚

æ¡ˆä¾‹ï¼šè±†ç“£ç”µå½±

```
# çˆ¬å–è±†ç“£ç”µå½±å‰10é¡µæ•°æ®
# https://movie.douban.com/j/chart/top_list?type=20&interval_id=100%3A90&action=&start=0&limit=20
# https://movie.douban.com/j/chart/top_list?type=20&interval_id=100%3A90&action=&start=20&limit=20
# https://movie.douban.com/j/chart/top_list?type=20&interval_id=100%3A90&action=&start=40&limit=20

import urllib.request
import urllib.parse

# ä¸‹è½½å‰10é¡µæ•°æ®
# ä¸‹è½½çš„æ­¥éª¤ï¼š1.è¯·æ±‚å¯¹è±¡çš„å®šåˆ¶  2.è·å–å“åº”çš„æ•°æ® 3.ä¸‹è½½

# æ¯æ‰§è¡Œä¸€æ¬¡è¿”å›ä¸€ä¸ªrequestå¯¹è±¡
def create_request(page):
    base_url = 'https://movie.douban.com/j/chart/top_list?type=20&interval_id=100%3A90&action=&'
    headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36'
    }
    data={
        #  1 2  3  4
        #  0 20 40 60
        'start':(page-1)*20,
        'limit':20
    }
    # dataç¼–ç 
    data = urllib.parse.urlencode(data)
    url = base_url + data
    request = urllib.request.Request(url=url,headers=headers)
    return request
# è·å–ç½‘é¡µæºç 
def get_content(request):
    response = urllib.request.urlopen(request)
    content = response.read().decode('utf-8')
    return content

def down_load(page,content):
#    with openï¼ˆæ–‡ä»¶çš„åå­—ï¼Œæ¨¡å¼ï¼Œç¼–ç ï¼‰as fp:
#        fp.write(å†…å®¹)
    with open('douban_'+str(page)+'.json','w',encoding='utf-8')as fp:
        fp.write(content)

if __name__ == '__main__':
    start_page = int(input('è¯·è¾“å…¥èµ·å§‹é¡µç '))
    end_page = int(input('è¯·è¾“å…¥ç»“æŸé¡µç '))
    for page in range(start_page,end_page+1):
        request = create_request(page)
        content = get_content(request)
        down_load(page,content)

```

#### ajaxçš„postè¯·æ±‚

æ¡ˆä¾‹ï¼šKFCå®˜ç½‘

#### å¤æ‚get

æ¡ˆä¾‹ï¼šç™¾åº¦è´´å§



æ‰©å±•ï¼šCURLï¼ˆè®¿é—®æœåŠ¡å™¨è·å–é¡µé¢æºç ï¼‰

```
1.æŸ¥çœ‹curlç‰ˆæœ¬
2.curlåŸºæœ¬ä½¿ç”¨
		ï¼ˆ1ï¼‰è®¿é—®é¡µé¢ egï¼šcurl http://www.baidu.com
		 (2)æºå¸¦UA   eg: curl -A 'Chrome' http://www.baidu.com
		 (3)postè¯·æ±‚ egï¼šcurl -X POST http://httpbin.org/post

```



